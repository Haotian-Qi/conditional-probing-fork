input_fields: &id_input_fields
  - newdoc_id
  - sent_id
  - text

cache: &id_cache !WholeDatasetCache
  train_path: &idtrainpath distilbert/dataset/train.ontonotes.withdep.conll
  dev_path: &iddevpath distilbert/dataset/dev.ontonotes.withdep.conll
  test_path: &idtestpath distilbert/dataset/test.ontonotes.withdep.conll

disk_reader: !OntonotesReader &id_disk_reader
  args: 
    - device: cpu:0
  train_path: *idtrainpath 
  dev_path: *iddevpath 
  test_path: *idtestpath 
  cache: *id_cache

dataset: !ListDataset
  args: 
    device: cpu:0
  data_loader: *id_disk_reader
  output_dataset: !AnnotationDataset
    args: 
      device: cpu:0
    task: !SentenceClassificationTask
      args: 
        device: cpu:0
      task_name: dep_rel
  input_datasets:
    - !HuggingfaceData
      args:
        device: cpu:0
      model_string: &model1string distilbert-base-uncased
      cache: *id_cache

model: !ListModel
  args: 
    device: cpu:0
  models:
    - !HuggingfaceModel
        args:
          device: cpu:0
        model_string: *model1string
        trainable: False
        index: 5

probe: !SentenceLinearLabelProbe
  args:
    device: cpu:0
  model_dim: 768
  label_space_size: 3

regimen: !ProbeRegimen
  args:
    device: cpu:0
  max_epochs: 50
  params_path: params
  reporting_root: &id_reporting_root distilbert/report/layer5.yaml.results

reporter: !IndependentLabelReporter
  args:
    device: cpu:0
  reporting_root: *id_reporting_root
  reporting_methods:
    - label_accuracy
    - v_entropy