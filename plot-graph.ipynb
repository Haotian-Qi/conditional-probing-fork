{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04363091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.13.1-cp39-cp39-win_amd64.whl (162.5 MB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ilya jeff\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (4.2.0)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.13.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe and torchrun.exe are installed in 'c:\\Users\\Ilya Jeff\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 20.2.3; however, version 23.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Ilya Jeff\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44c5a974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import glob\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"whitegrid\")\n",
    "mpl.rcParams['agg.path.chunksize'] = 10000\n",
    "\n",
    "#from matplotlib import rc\n",
    "#rc('text', usetex=True)\n",
    "mpl.rcParams['axes.titlesize'] = 'xx-large'\n",
    "mpl.rcParams['axes.labelsize'] = 'xx-large'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "033d4333",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun_rounds = ['round1', 'round2', 'round3']\n",
    "def get_avg_results(path_string):\n",
    "  \"\"\"\n",
    "  For experiments with multiple random training runs, collects all\n",
    "  training runs and averages their results\n",
    "  \"\"\"\n",
    "  result_list = []\n",
    "  for rerun_string in rerun_rounds:\n",
    "    completed_path = path_string.format(rerun_string)\n",
    "    if os.path.exists(completed_path):\n",
    "      result_list.append(float(open(completed_path).read()))\n",
    "  return sum(result_list)/len(result_list) if len(result_list) > 0 else -1.0\n",
    "  #print(result_list)\n",
    "  #return np.std(result_list) if len(result_list) > 0 else -1 #sum(result_list)/len(result_list) if len(result_list) > 0 else -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "93a1b410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.1029, 4.0838, 4.0796, 4.0765, 4.0777, 4.0805, 4.0839, 4.0834, 4.0885,\n",
      "        4.0911, 4.0936, 4.1009])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([get_avg_results('reports/layer{}-0.yaml.results/dev.v_entropy'.format(i)) for i in range(1,13)])\n",
    "b = torch.tensor([float(open('reports/layer{}-0.yaml.results/dev.v_entropy'.format(i)).read().strip()) for i in range(1,13)])\n",
    "c = get_avg_results('reports/layer0.yaml.results/dev.v_entropy')\n",
    "print(c)\n",
    "\n",
    "#for i in range(1,13):\n",
    "#   print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50abab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_layerwise_zero_baseline():\n",
    "    fig, ax = plt.subplots(figsize=(6,4.5))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "    ax.set_xticks(list(range(1,13)))\n",
    "    \"\"\"Makes a plot comparing layerwise bits of info\"\"\"\n",
    "\n",
    "    task_768_twolayer_ventropy = torch.tensor([get_avg_results('reports/layer{}-0.yaml.results/dev.v_entropy'.format(i)) for i in range(1,13)])\n",
    "    task_768_embedding_layer_ventropy = get_avg_results('reports/layer0.yaml.results/dev.v_entropy')\n",
    "    #task_768_twolayer_ventropy = torch.tensor([float(open('reports/layer{}-0.yaml.results/dev.v_entropy'.format(i)).read().strip()) for i in range(1,13)])\n",
    "    #task_768_embedding_layer_ventropy = float(open('reports/layer0.yaml.results/dev.v_entropy').read().strip())\n",
    "    x_range = list(range(1,13))\n",
    "    plt.plot(x_range, task_768_embedding_layer_ventropy-task_768_twolayer_ventropy, label=r'conditional')\n",
    "    plt.title('roberta dep rel')\n",
    "    plt.ylabel('Bits')\n",
    "    plt.xlabel('Model layer')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('roberta dep rel', dpi=200)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b21e8ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_layerwise_zero_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f5a72c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "bdcb088fcff89543e4432dbe4ebd8623f44d6acef8abb4374116cf95ee7b50fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
