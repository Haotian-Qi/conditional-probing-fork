{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04363091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.13.1-cp39-cp39-win_amd64.whl (162.5 MB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ilya jeff\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (4.2.0)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.13.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe and torchrun.exe are installed in 'c:\\Users\\Ilya Jeff\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 20.2.3; however, version 23.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Ilya Jeff\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44c5a974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import glob\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"whitegrid\")\n",
    "mpl.rcParams['agg.path.chunksize'] = 10000\n",
    "\n",
    "#from matplotlib import rc\n",
    "#rc('text', usetex=True)\n",
    "mpl.rcParams['axes.titlesize'] = 'xx-large'\n",
    "mpl.rcParams['axes.labelsize'] = 'xx-large'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "033d4333",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun_rounds = ['round1', 'round2', 'round3']\n",
    "def get_avg_results(path_string):\n",
    "  \"\"\"\n",
    "  For experiments with multiple random training runs, collects all\n",
    "  training runs and averages their results\n",
    "  \"\"\"\n",
    "  result_list = []\n",
    "  for rerun_string in rerun_rounds:\n",
    "    completed_path = path_string.format(rerun_string)\n",
    "    if os.path.exists(completed_path):\n",
    "      result_list.append(float(open(completed_path).read()))\n",
    "  return sum(result_list)/len(result_list) if len(result_list) > 0 else -1.0\n",
    "  #print(result_list)\n",
    "  #return np.std(result_list) if len(result_list) > 0 else -1 #sum(result_list)/len(result_list) if len(result_list) > 0 else -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "93a1b410",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = torch.tensor([get_avg_results('reports/dep_rel-6-768-en-distilbert-layer{}.yaml.results/dev.v_entropy'.format(i)) for i in range(1,7)])\n",
    "#b = torch.tensor([float(open('reports/dep_rel-6-768-en-distilbert-layer{}.yaml.results/dev.v_entropy'.format(i)).read().strip()) for i in range(1,7)])\n",
    "#c = get_avg_results('reports/layer0.yaml.results/dev.v_entropy')\n",
    "#print(a)\n",
    "#print(b)\n",
    "\n",
    "#for i in range(1,7):\n",
    "#   print(i-1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50abab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_layerwise_zero_baseline(task, model):\n",
    "    fig, ax = plt.subplots(figsize=(6,4.5))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "    #change depending on layers\n",
    "    ax.set_xticks(list(range(1,11)))\n",
    "    \"\"\"Makes a plot comparing layerwise bits of info\"\"\"\n",
    "    #change range depending on layers of model\n",
    "    task_768_singlelayer_ventropy = torch.tensor([get_avg_results('reports/{}-{}-layer{}.yaml.results/dev.v_entropy'.format(task,model,i)) for i in range(1,11)])\n",
    "    task_768_twolayer_ventropy = torch.tensor([get_avg_results('reports/{}-{}-layer{}-0.yaml.results/dev.v_entropy'.format(task,model,i)) for i in range(1,11)])\n",
    "    task_768_embedding_layer_ventropy = get_avg_results('reports/{}-{}-layer0.yaml.results/dev.v_entropy'.format(task,model))\n",
    "\n",
    "    #print(task_768_singlelayer_ventropy)\n",
    "    #print(task_768_twolayer_ventropy)\n",
    "    #print(task_768_embedding_layer_ventropy)\n",
    "\n",
    "    #12 layer\n",
    "    #x_range = list(range(1,13))\n",
    "\n",
    "    #6 layer\n",
    "    #x_range = list(range(1,7))\n",
    "\n",
    "    #3 layer\n",
    "    #x_range = list(range(1,4))\n",
    "\n",
    "    #8 layer\n",
    "    #x_range = list(range(1,9))\n",
    "\n",
    "    #10 layer\n",
    "    x_range = list(range(1,11))\n",
    "\n",
    "    plt.plot(x_range, task_768_embedding_layer_ventropy-task_768_singlelayer_ventropy, label=r'baselined')\n",
    "    plt.plot(x_range, task_768_embedding_layer_ventropy-task_768_twolayer_ventropy, label=r'conditional')\n",
    "\n",
    "    #plot title\n",
    "    plt.title('{} {}'.format(model,task), fontsize = 12)\n",
    "\n",
    "    plt.ylabel('Bits', fontsize = 12)\n",
    "    plt.xlabel('Model layer', fontsize = 12)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #save figure in folder\n",
    "    plt.savefig('graphs/{0}/{0} {1}.png'.format(model,task), dpi=200)\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a47a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_layerwise_zero_baseline('dep_rel','distilbert-b64-L10')\n",
    "plot_layerwise_zero_baseline('named_entities','distilbert-b64-L10')\n",
    "plot_layerwise_zero_baseline('ptb_pos','distilbert-b64-L10')\n",
    "plot_layerwise_zero_baseline('upos','distilbert-b64-L10')\n",
    "plot_layerwise_zero_baseline('word_sense','distilbert-b64-L10')\n",
    "plot_layerwise_zero_baseline('sst2','distilbert-b64-L10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "430bbd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(task, model):\n",
    "    fig, ax = plt.subplots(figsize=(6,4.5))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "    #change depending on layers\n",
    "    ax.set_xticks(list(range(1,11)))\n",
    "    \"\"\"Makes a plot accuracy\"\"\"\n",
    "    #change range depending on layers of model\n",
    "    label_accuracy = torch.tensor([get_avg_results('reports/{}-{}-layer{}.yaml.results/dev.label_acc'.format(task,model,i)) for i in range(1,11)])\n",
    "\n",
    "    #print(label_accuracy)\n",
    "\n",
    "    #12 layer\n",
    "    #x_range = list(range(1,13))\n",
    "\n",
    "    #6 layer\n",
    "    #x_range = list(range(1,7))\n",
    "\n",
    "    #3 layer\n",
    "    #x_range = list(range(1,4))\n",
    "\n",
    "    #8 layer\n",
    "    #x_range = list(range(1,9))\n",
    "\n",
    "    #10 layer\n",
    "    x_range = list(range(1,11))\n",
    "\n",
    "    plt.plot(x_range, label_accuracy)\n",
    "\n",
    "    #plot title\n",
    "    plt.title('{} {} accuracy'.format(model,task), fontsize = 12)\n",
    "\n",
    "    plt.ylabel('Accuracy', fontsize = 12)\n",
    "    plt.xlabel('Model layer', fontsize = 12)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #save figure in folder\n",
    "    plt.savefig('graphs/{0}/{0} {1} accuracy.png'.format(model,task), dpi=200)\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480cbd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy('dep_rel','distilbert-b64-L10')\n",
    "plot_accuracy('named_entities','distilbert-b64-L10')\n",
    "plot_accuracy('ptb_pos','distilbert-b64-L10')\n",
    "plot_accuracy('upos','distilbert-b64-L10')\n",
    "plot_accuracy('word_sense','distilbert-b64-L10')\n",
    "plot_accuracy('sst2','distilbert-b64-L10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "403af950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_official_berts(task):\n",
    "    fig, ax = plt.subplots(figsize=(10,4.5))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "    #change depending on layers\n",
    "    ax.set_xticks(list(range(1,13)))\n",
    "    \"\"\"Makes a plot comparing layerwise bits of info\"\"\"\n",
    "    #bert768\n",
    "    label_accuracy_bert768 = torch.tensor([get_avg_results('reports/{}-bert768-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,13)])\n",
    "\n",
    "    #bert-l2-prune30\n",
    "    label_accuracy_bert_l2_prune30 = torch.tensor([get_avg_results('reports/{}-bert-l2-prune30-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,13)])\n",
    "\n",
    "    #distilbert-base-uncased\n",
    "    label_accuracy_distilbert_base_uncased = torch.tensor([get_avg_results('reports/{}-distilbert-base-uncased-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,7)])\n",
    "\n",
    "    #MiniLMv2-L6-H768-distilled-from-BERT-Base\n",
    "    label_accuracy_minilmv2 = torch.tensor([get_avg_results('reports/{}-MiniLMv2-L6-H768-distilled-from-BERT-Base-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,7)])\n",
    "\n",
    "    #print(label_accuracy)\n",
    "\n",
    "    #12 layer\n",
    "    x_range1 = list(range(1,13))\n",
    "    #3 layer\n",
    "    x_range2 = np.linspace(1,12,3)\n",
    "    #6 layer\n",
    "    x_range3 = np.linspace(1,12,6)\n",
    "    #8 layer\n",
    "    x_range4 = np.linspace(1,12,8)\n",
    "    #10 layer\n",
    "    x_range5 = np.linspace(1,12,10)\n",
    "\n",
    "    plt.plot(x_range1, label_accuracy_bert768, label=r'bert_768', color='red')\n",
    "    plt.plot(x_range3, label_accuracy_distilbert_base_uncased, label=r'distilbert-base-uncased', color='green')\n",
    "    plt.plot(x_range3, label_accuracy_minilmv2, label=r'MiniLMv2', color='blue')\n",
    "    plt.plot(x_range1, label_accuracy_bert_l2_prune30, label=r'bert-l2-prune30', color='darkorange')\n",
    "\n",
    "    plt.title('Accuracy of {} for variants of bert scaled for 12 layers'.format(task), fontsize = 12)\n",
    "\n",
    "    plt.ylabel('Accuracy', fontsize = 12)\n",
    "    plt.xlabel('Model layer', fontsize = 12)\n",
    "    #plt.legend()\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left', fontsize = \"small\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig('graphs/Accuracies/Accuracies for {} original bert variants scaled to 12 layers.png'.format(task), dpi=200)\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d95273b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_official_berts('dep_rel')\n",
    "plot_accuracy_official_berts('named_entities')\n",
    "plot_accuracy_official_berts('ptb_pos')\n",
    "plot_accuracy_official_berts('upos')\n",
    "plot_accuracy_official_berts('word_sense')\n",
    "plot_accuracy_official_berts('sst2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c4b9918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conditional_official_bert(task):\n",
    "    fig, ax = plt.subplots(figsize=(10,4.5))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "    #change depending on layers\n",
    "    ax.set_xticks(list(range(1,13)))\n",
    "    \"\"\"Makes a plot comparing layerwise bits of info\"\"\"\n",
    "    #bert768\n",
    "    twolayer_bert768 = torch.tensor([get_avg_results('reports/{}-bert768-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,13)])\n",
    "    embedded1 = get_avg_results('reports/{}-bert768-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_bert768 = embedded1 - twolayer_bert768\n",
    "\n",
    "    #bert-l2-prune30\n",
    "    twolayer_bertl2 = torch.tensor([get_avg_results('reports/{}-bert-l2-prune30-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,13)])\n",
    "    embedded2 = get_avg_results('reports/{}-bert-l2-prune30-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditiona_l2 = embedded2 - twolayer_bertl2\n",
    "\n",
    "    #distilbert-base-uncased\n",
    "    twolayer_distil = torch.tensor([get_avg_results('reports/{}-distilbert-base-uncased-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,7)])\n",
    "    embedded3 = get_avg_results('reports/{}-distilbert-base-uncased-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_distil = embedded3 - twolayer_distil\n",
    "\n",
    "    #MiniLMv2-L6-H768-distilled-from-BERT-Base\n",
    "    twolayer_minilmv2 = torch.tensor([get_avg_results('reports/{}-MiniLMv2-L6-H768-distilled-from-BERT-Base-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,7)])\n",
    "    embedded13 = get_avg_results('reports/{}-MiniLMv2-L6-H768-distilled-from-BERT-Base-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_minilmv2 = embedded13 - twolayer_minilmv2\n",
    "\n",
    "    #print(label_accuracy)\n",
    "\n",
    "    #12 layer\n",
    "    x_range1 = list(range(1,13))\n",
    "    #3 layer\n",
    "    x_range2 = np.linspace(1,12,3)\n",
    "    #6 layer\n",
    "    x_range3 = np.linspace(1,12,6)\n",
    "    #8 layer\n",
    "    x_range4 = np.linspace(1,12,8)\n",
    "    #10 layer\n",
    "    x_range5 = np.linspace(1,12,10)\n",
    "\n",
    "    plt.plot(x_range1, conditional_bert768, label=r'bert_768', color='red')\n",
    "    plt.plot(x_range3, conditional_distil, label=r'distilbert-base-uncased', color='green')\n",
    "    plt.plot(x_range3, conditional_minilmv2, label=r'MiniLMv2', color='blue')\n",
    "    plt.plot(x_range1, conditiona_l2, label=r'bert-l2-prune30', color='darkorange')\n",
    "\n",
    "    plt.title('V-Entropy of {} for variants of bert scaled for 12 layers'.format(task), fontsize = 12)\n",
    "\n",
    "    plt.ylabel('Accuracy', fontsize = 12)\n",
    "    plt.xlabel('Model layer', fontsize = 12)\n",
    "    #plt.legend()\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left', fontsize = \"small\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig('graphs/V-Entropy/V-Entropy for {} original bert variants scaled to 12 layers.png'.format(task), dpi=200)\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e03e3629",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_conditional_official_bert('dep_rel')\n",
    "plot_conditional_official_bert('named_entities')\n",
    "plot_conditional_official_bert('ptb_pos')\n",
    "plot_conditional_official_bert('upos')\n",
    "plot_conditional_official_bert('word_sense')\n",
    "plot_conditional_official_bert('sst2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1a0bdb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_experiments(task):\n",
    "    fig, ax = plt.subplots(figsize=(10,4.5))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "    #change depending on layers\n",
    "    ax.set_xticks(list(range(1,13)))\n",
    "    \"\"\"Makes a plot comparing layerwise bits of info\"\"\"\n",
    "    #3-768-distilbert\n",
    "    label_accuracy_3_768 = torch.tensor([get_avg_results('reports/{}-3-768-en-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,4)])\n",
    "\n",
    "    #6-768-distilbert\n",
    "    label_accuracy_6_768 = torch.tensor([get_avg_results('reports/{}-6-768-en-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,7)])\n",
    "\n",
    "    #6-b128-distilbert\n",
    "    label_accuracy_6_b128 = torch.tensor([get_avg_results('reports/{}-6-b128-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,7)])\n",
    "\n",
    "    #6-768-b32-distilbert\n",
    "    label_accuracy_6_768_b32 = torch.tensor([get_avg_results('reports/{}-6-768-b32-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,7)])\n",
    "\n",
    "    #distilbert-b64-L6\n",
    "    label_accuracy_6_b64 = torch.tensor([get_avg_results('reports/{}-distilbert-b64-L6-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,7)])\n",
    "\n",
    "    #8-768-distilbert\n",
    "    label_accuracy_8_768 = torch.tensor([get_avg_results('reports/{}-8-768-en-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,9)])\n",
    "\n",
    "    #8-b128-distilbert\n",
    "    label_accuracy_8_b128 = torch.tensor([get_avg_results('reports/{}-8-b128-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,9)])\n",
    "\n",
    "    #8-768-s9273-distilbert\n",
    "    label_accuracy_8_768_s9273 = torch.tensor([get_avg_results('reports/{}-8-768-en-s9273-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,9)])\n",
    "\n",
    "    #distilbert-b64-L8\n",
    "    label_accuracy_8_b64 = torch.tensor([get_avg_results('reports/{}-distilbert-b64-L8-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,9)])\n",
    "\n",
    "    #10-768-distilbert\n",
    "    label_accuracy_10_768 = torch.tensor([get_avg_results('reports/{}-10-768-en-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,11)])\n",
    "\n",
    "    #10-b128-distilbert\n",
    "    label_accuracy_10_b128 = torch.tensor([get_avg_results('reports/{}-10-b128-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,11)])\n",
    "\n",
    "    #distilbert-b64-L10\n",
    "    label_accuracy_10_b64 = torch.tensor([get_avg_results('reports/{}-distilbert-b64-L10-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,11)])\n",
    "\n",
    "    #12-768-distilbert\n",
    "    label_accuracy_12_768 = torch.tensor([get_avg_results('reports/{}-12-768-en-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,13)])\n",
    "\n",
    "    #12-b128-distilbert\n",
    "    label_accuracy_12_b128 = torch.tensor([get_avg_results('reports/{}-12-b128-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,13)])\n",
    "\n",
    "    #distilbert-b64-L12\n",
    "    #label_accuracy_12_b64 = torch.tensor([get_avg_results('reports/{}-distilbert-b64-L12-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,13)])\n",
    "\n",
    "    #print(label_accuracy)\n",
    "\n",
    "    #12 layer\n",
    "    x_range1 = list(range(1,13))\n",
    "    #3 layer\n",
    "    x_range2 = np.linspace(1,12,3)\n",
    "    #6 layer\n",
    "    x_range3 = np.linspace(1,12,6)\n",
    "    #8 layer\n",
    "    x_range4 = np.linspace(1,12,8)\n",
    "    #10 layer\n",
    "    x_range5 = np.linspace(1,12,10)\n",
    "\n",
    "    plt.plot(x_range2, label_accuracy_3_768, label=r'3-768-distilbert', color='red')\n",
    "    plt.plot(x_range3, label_accuracy_6_768, label=r'6-768-distilbert', color='green')\n",
    "    plt.plot(x_range3, label_accuracy_6_768_b32, label=r'6-768-b32-distilbert', color='blue')\n",
    "    plt.plot(x_range3, label_accuracy_6_b128, label=r'6-b128-distilbert', color='yellow')\n",
    "    plt.plot(x_range3, label_accuracy_6_b64, label=r'distilbert-b64-L6', color='orange')\n",
    "    plt.plot(x_range4, label_accuracy_8_768, label=r'8-768-distilbert', color='purple')\n",
    "    plt.plot(x_range4, label_accuracy_8_b128, label=r'8-b128-distilbert', color='brown')\n",
    "    plt.plot(x_range4, label_accuracy_8_b64, label=r'distilbert-b64-L8', color='hotpink')\n",
    "    plt.plot(x_range4, label_accuracy_8_768_s9273, label=r'8-768-s9273-distilbert', color='teal')\n",
    "    plt.plot(x_range5, label_accuracy_10_768, label=r'10-768-distilbert', color='maroon')\n",
    "    plt.plot(x_range5, label_accuracy_10_b128, label=r'10-b128-distilbert', color='cyan')\n",
    "    plt.plot(x_range5, label_accuracy_10_b64, label=r'distilbert-b64-L10', color='black')\n",
    "    plt.plot(x_range1, label_accuracy_12_768, label=r'12-768-distilbert', color='grey')\n",
    "    plt.plot(x_range1, label_accuracy_12_b128, label=r'12-b128-distilbert', color='lime')\n",
    "    #plt.plot(x_range5, label_accuracy_12_b64, label=r'distilbert-b64-L12', color='olive')\n",
    "\n",
    "\n",
    "\n",
    "    plt.title('Accuracy of {} for variants of bert scaled for 12 layers'.format(task), fontsize = 12)\n",
    "\n",
    "    plt.ylabel('Accuracy', fontsize = 12)\n",
    "    plt.xlabel('Model layer', fontsize = 12)\n",
    "    #plt.legend()\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left', fontsize = \"small\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig('graphs/Accuracies/Accuracies for {} experiments of bert scaled to 12 layers.png'.format(task), dpi=200)\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c13add34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_experiments('dep_rel')\n",
    "plot_accuracy_experiments('named_entities')\n",
    "plot_accuracy_experiments('ptb_pos')\n",
    "plot_accuracy_experiments('upos')\n",
    "plot_accuracy_experiments('word_sense')\n",
    "plot_accuracy_experiments('sst2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fa04876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conditional_experiments(task):\n",
    "    fig, ax = plt.subplots(figsize=(10,4.5))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "    #change depending on layers\n",
    "    ax.set_xticks(list(range(1,13)))\n",
    "    \"\"\"Makes a plot comparing layerwise bits of info\"\"\"\n",
    "    #3-768-distilbert\n",
    "    twolayer_3_768 = torch.tensor([get_avg_results('reports/{}-3-768-en-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,4)])\n",
    "    embedded7 = get_avg_results('reports/{}-3-768-en-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_3_768 = embedded7 - twolayer_3_768\n",
    "\n",
    "    #6-768-distilbert\n",
    "    twolayer_6_768 = torch.tensor([get_avg_results('reports/{}-6-768-en-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,7)])\n",
    "    embedded4 = get_avg_results('reports/{}-6-768-en-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_6_768 = embedded4 - twolayer_6_768\n",
    "\n",
    "    #6-b128-distilbert\n",
    "    twolayer_6_b128 = torch.tensor([get_avg_results('reports/{}-6-b128-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,7)])\n",
    "    embedded5 = get_avg_results('reports/{}-6-b128-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional5_6_b128 = embedded5 - twolayer_6_b128\n",
    "\n",
    "    #6-768-b32-distilbert\n",
    "    twolayer_6_b32 = torch.tensor([get_avg_results('reports/{}-6-768-b32-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,7)])\n",
    "    embedded6 = get_avg_results('reports/{}-6-768-b32-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_6_b32 = embedded6 - twolayer_6_b32\n",
    "\n",
    "    #distilbert-b64-L6\n",
    "    twolayer_6_b64 = torch.tensor([get_avg_results('reports/{}-distilbert-b64-L6-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,7)])\n",
    "    embeddedb64 = get_avg_results('reports/{}-distilbert-b64-L6-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_6_b64 = embeddedb64 - twolayer_6_b64\n",
    "\n",
    "    #8-768-distilbert\n",
    "    twolayer_8_768 = torch.tensor([get_avg_results('reports/{}-8-768-en-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,9)])\n",
    "    embedded8 = get_avg_results('reports/{}-8-768-en-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_8_768 = embedded8 - twolayer_8_768\n",
    "\n",
    "    #8-b128-distilbert\n",
    "    twolayer_8_b128 = torch.tensor([get_avg_results('reports/{}-8-b128-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,9)])\n",
    "    embedded8b128 = get_avg_results('reports/{}-8-b128-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_8_b128 = embedded8b128 - twolayer_8_b128\n",
    "\n",
    "    #8-768-s9273-distilbert\n",
    "    twolayer_8_768_S9273 = torch.tensor([get_avg_results('reports/{}-8-768-en-s9273-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,9)])\n",
    "    embedded9 = get_avg_results('reports/{}-8-768-en-s9273-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_8_s9273 = embedded9 - twolayer_8_768_S9273\n",
    "\n",
    "    #distilbert-b64-L8\n",
    "    twolayer_8_b64 = torch.tensor([get_avg_results('reports/{}-distilbert-b64-L8-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,9)])\n",
    "    embedded8b64 = get_avg_results('reports/{}-distilbert-b64-L8-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_8_b64 = embedded8b64 - twolayer_8_b64\n",
    "\n",
    "    #10-768-distilbert\n",
    "    twolayer_10_768 = torch.tensor([get_avg_results('reports/{}-10-768-en-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,11)])\n",
    "    embedded10 = get_avg_results('reports/{}-10-768-en-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_10_768 = embedded10 - twolayer_10_768\n",
    "\n",
    "    #10-b128-distilbert\n",
    "    twolayer_10_b128 = torch.tensor([get_avg_results('reports/{}-10-b128-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,11)])\n",
    "    embedded11 = get_avg_results('reports/{}-10-b128-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_10_b128 = embedded11 - twolayer_10_b128\n",
    "\n",
    "    #distilbert-b64-L10\n",
    "    twolayer_10_b64 = torch.tensor([get_avg_results('reports/{}-distilbert-b64-L10-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,11)])\n",
    "    embedded10b64 = get_avg_results('reports/{}-distilbert-b64-L10-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_10_b64 = embedded10b64 - twolayer_10_b64\n",
    "\n",
    "    #12-768-distilbert\n",
    "    twolayer_12_768 = torch.tensor([get_avg_results('reports/{}-12-768-en-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,13)])\n",
    "    embedded12 = get_avg_results('reports/{}-12-768-en-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_12_768 = embedded12 - twolayer_12_768\n",
    "\n",
    "    #12-b128-distilbert\n",
    "    twolayer_12_b128 = torch.tensor([get_avg_results('reports/{}-12-b128-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,13)])\n",
    "    embedded12b128 = get_avg_results('reports/{}-12-b128-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_12_b128 = embedded12b128 - twolayer_12_b128\n",
    "\n",
    "    #distilbert-b64-L12\n",
    "    # twolayer_12_b64 = torch.tensor([get_avg_results('reports/{}-distilbert-b64-L12-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,13)])\n",
    "    # embedded12b64 = get_avg_results('reports/{}-distilbert-b64-L12-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    # conditional_12_b64 = embedded12b64 - twolayer_12_b64\n",
    "\n",
    "    #print(label_accuracy)\n",
    "\n",
    "    #12 layer\n",
    "    x_range1 = list(range(1,13))\n",
    "    #3 layer\n",
    "    x_range2 = np.linspace(1,12,3)\n",
    "    #6 layer\n",
    "    x_range3 = np.linspace(1,12,6)\n",
    "    #8 layer\n",
    "    x_range4 = np.linspace(1,12,8)\n",
    "    #10 layer\n",
    "    x_range5 = np.linspace(1,12,10)\n",
    "\n",
    "    plt.plot(x_range2, conditional_3_768, label=r'3-768-distilbert', color='red')\n",
    "    plt.plot(x_range3, conditional_6_768, label=r'6-768-distilbert', color='green')\n",
    "    plt.plot(x_range3, conditional_6_b32, label=r'6-768-b32-distilbert', color='blue')\n",
    "    plt.plot(x_range3, conditional5_6_b128, label=r'6-b128-distilbert', color='yellow')\n",
    "    plt.plot(x_range3, conditional_6_b64, label=r'distilbert-b64-L6', color='orange')\n",
    "    plt.plot(x_range4, conditional_8_768, label=r'8-768-distilbert', color='purple')\n",
    "    plt.plot(x_range4, conditional_8_b128, label=r'8-b128-distilbert', color='brown')\n",
    "    plt.plot(x_range4, conditional_8_b64, label=r'distilbert-b64-L8', color='hotpink')\n",
    "    plt.plot(x_range4, conditional_8_s9273, label=r'8-768-s9273-distilbert', color='teal')\n",
    "    plt.plot(x_range5, conditional_10_768, label=r'10-768-distilbert', color='maroon')\n",
    "    plt.plot(x_range5, conditional_10_b128, label=r'10-b128-distilbert', color='cyan')\n",
    "    plt.plot(x_range5, conditional_10_b64, label=r'distilbert-b64-L10', color='black')\n",
    "    plt.plot(x_range1, conditional_12_768, label=r'12-768-distilbert', color='grey')\n",
    "    plt.plot(x_range1, conditional_12_b128, label=r'12-b128-distilbert', color='lime')\n",
    "    #plt.plot(x_range1, conditional_12_b64, label=r'distilbert-b64-L12', color='olive')\n",
    "\n",
    "    plt.title('V-Entropy of {} for variants of bert scaled for 12 layers'.format(task), fontsize = 12)\n",
    "\n",
    "    plt.ylabel('Accuracy', fontsize = 12)\n",
    "    plt.xlabel('Model layer', fontsize = 12)\n",
    "    #plt.legend()\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left', fontsize = \"small\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig('graphs/V-Entropy/V-Entropy for {} experiments of bert scaled to 12 layers.png'.format(task), dpi=200)\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "777798fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_conditional_experiments('dep_rel')\n",
    "plot_conditional_experiments('named_entities')\n",
    "plot_conditional_experiments('ptb_pos')\n",
    "plot_conditional_experiments('upos')\n",
    "plot_conditional_experiments('word_sense')\n",
    "plot_conditional_experiments('sst2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c9cf0bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_combined(task):\n",
    "    fig, ax = plt.subplots(figsize=(10,4.5))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "    #change depending on layers\n",
    "    ax.set_xticks(list(range(1,13)))\n",
    "    \"\"\"Makes a plot comparing layerwise bits of info\"\"\"\n",
    "    #bert768\n",
    "    label_accuracy_bert768 = torch.tensor([get_avg_results('reports/{}-bert768-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,13)])\n",
    "\n",
    "    #bert-l2-prune30\n",
    "    label_accuracy_bert_l2_prune30 = torch.tensor([get_avg_results('reports/{}-bert-l2-prune30-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,13)])\n",
    "\n",
    "    #distilbert-base-uncased\n",
    "    label_accuracy_distilbert_base_uncased = torch.tensor([get_avg_results('reports/{}-distilbert-base-uncased-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,7)])\n",
    "\n",
    "    #MiniLMv2-L6-H768-distilled-from-BERT-Base\n",
    "    label_accuracy_minilmv2 = torch.tensor([get_avg_results('reports/{}-MiniLMv2-L6-H768-distilled-from-BERT-Base-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,7)])\n",
    "\n",
    "    #3-768-distilbert\n",
    "    label_accuracy_3_768 = torch.tensor([get_avg_results('reports/{}-3-768-en-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,4)])\n",
    "\n",
    "    #6-768-distilbert\n",
    "    label_accuracy_6_768 = torch.tensor([get_avg_results('reports/{}-6-768-en-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,7)])\n",
    "\n",
    "    #6-b128-distilbert\n",
    "    label_accuracy_6_b128 = torch.tensor([get_avg_results('reports/{}-6-b128-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,7)])\n",
    "\n",
    "    #6-768-b32-distilbert\n",
    "    label_accuracy_6_768_b32 = torch.tensor([get_avg_results('reports/{}-6-768-b32-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,7)])\n",
    "\n",
    "    #distilbert-b64-L6\n",
    "    label_accuracy_6_b64 = torch.tensor([get_avg_results('reports/{}-distilbert-b64-L6-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,7)])\n",
    "\n",
    "    #8-768-distilbert\n",
    "    label_accuracy_8_768 = torch.tensor([get_avg_results('reports/{}-8-768-en-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,9)])\n",
    "\n",
    "    #8-b128-distilbert\n",
    "    label_accuracy_8_b128 = torch.tensor([get_avg_results('reports/{}-8-b128-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,9)])\n",
    "\n",
    "    #distilbert-b64-L8\n",
    "    label_accuracy_8_b64 = torch.tensor([get_avg_results('reports/{}-distilbert-b64-L8-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,9)])\n",
    "\n",
    "    #8-768-s9273-distilbert\n",
    "    label_accuracy_8_768_s9273 = torch.tensor([get_avg_results('reports/{}-8-768-en-s9273-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,9)])\n",
    "\n",
    "    #10-768-distilbert\n",
    "    label_accuracy_10_768 = torch.tensor([get_avg_results('reports/{}-10-768-en-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,11)])\n",
    "\n",
    "    #10-b128-distilbert\n",
    "    label_accuracy_10_b128 = torch.tensor([get_avg_results('reports/{}-10-b128-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,11)])\n",
    "\n",
    "    #distilbert-b64-L10\n",
    "    label_accuracy_10_b64 = torch.tensor([get_avg_results('reports/{}-distilbert-b64-L10-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,11)])\n",
    "\n",
    "    #12-768-distilbert\n",
    "    label_accuracy_12_768 = torch.tensor([get_avg_results('reports/{}-12-768-en-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,13)])\n",
    "\n",
    "    #12-b128-distilbert\n",
    "    label_accuracy_12_b128 = torch.tensor([get_avg_results('reports/{}-12-b128-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,13)])\n",
    "\n",
    "    #distilbert-b64-L12\n",
    "    #label_accuracy_12_b64 = torch.tensor([get_avg_results('reports/{}-distilbert-b64-L12-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,13)])\n",
    "\n",
    "    #print(label_accuracy)\n",
    "\n",
    "    #12 layer\n",
    "    x_range1 = list(range(1,13))\n",
    "    #3 layer\n",
    "    x_range2 = np.linspace(1,12,3)\n",
    "    #6 layer\n",
    "    x_range3 = np.linspace(1,12,6)\n",
    "    #8 layer\n",
    "    x_range4 = np.linspace(1,12,8)\n",
    "    #10 layer\n",
    "    x_range5 = np.linspace(1,12,10)\n",
    "\n",
    "    #plt.plot(x_range1, label_accuracy_bert768, label=r'bert_768')\n",
    "    #plt.plot(x_range3, label_accuracy_distilbert_base_uncased, label=r'distilbert-base-uncased')\n",
    "    #plt.plot(x_range3, label_accuracy_minilmv2, label=r'MiniLMv2')\n",
    "    #plt.plot(x_range1, label_accuracy_bert_l2_prune30, label=r'bert-l2-prune30')\n",
    "    plt.plot(x_range2, label_accuracy_3_768, label=r'3-768-distilbert')\n",
    "    plt.plot(x_range3, label_accuracy_6_768, label=r'6-768-distilbert')\n",
    "    plt.plot(x_range3, label_accuracy_6_768_b32, label=r'6-768-b32-distilbert')\n",
    "    plt.plot(x_range3, label_accuracy_6_b128, label=r'6-b128-distilbert')\n",
    "    plt.plot(x_range3, label_accuracy_6_b64, label=r'distilbert-b64-L6')\n",
    "    plt.plot(x_range4, label_accuracy_8_768, label=r'8-768-distilbert')\n",
    "    plt.plot(x_range4, label_accuracy_8_b128, label=r'8-b128-distilbert')\n",
    "    plt.plot(x_range4, label_accuracy_8_b64, label=r'distilbert-b64-L8')\n",
    "    plt.plot(x_range4, label_accuracy_8_768_s9273, label=r'8-768-s9273-distilbert')\n",
    "    plt.plot(x_range5, label_accuracy_10_768, label=r'10-768-distilbert')\n",
    "    plt.plot(x_range5, label_accuracy_10_b128, label=r'10-b128-distilbert')\n",
    "    plt.plot(x_range5, label_accuracy_10_b64, label=r'distilbert-b64-L10')\n",
    "    plt.plot(x_range1, label_accuracy_12_768, label=r'12-768-distilbert')\n",
    "    plt.plot(x_range1, label_accuracy_12_b128, label=r'12-b128-distilbert')\n",
    "    #plt.plot(x_range1, label_accuracy_12_b64, label=r'distilbert-b64-L12')\n",
    "\n",
    "    plt.title('Accuracy of {} for variants of bert scaled for 12 layers'.format(task), fontsize = 12)\n",
    "\n",
    "    plt.ylabel('Accuracy', fontsize = 12)\n",
    "    plt.xlabel('Model layer', fontsize = 12)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left', fontsize = \"small\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #plt.savefig('graphs/Accuracies/Accuracies for {} bert768 variants scaled to 12 layers.png'.format(task), dpi=200)\n",
    "    plt.savefig('graphs/Accuracies/Accuracies for {} wo bert768 scaled to 12 layers.png'.format(task), dpi=200)\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5f684f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_combined('dep_rel')\n",
    "plot_accuracy_combined('named_entities')\n",
    "plot_accuracy_combined('ptb_pos')\n",
    "plot_accuracy_combined('upos')\n",
    "plot_accuracy_combined('word_sense')\n",
    "plot_accuracy_combined('sst2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "61363f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conditional_combined(task):\n",
    "    fig, ax = plt.subplots(figsize=(10,4.5))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "    #change depending on layers\n",
    "    ax.set_xticks(list(range(1,13)))\n",
    "    \"\"\"Makes a plot comparing layerwise bits of info\"\"\"\n",
    "    #bert768\n",
    "    twolayer_bert768 = torch.tensor([get_avg_results('reports/{}-bert768-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,13)])\n",
    "    embedded1 = get_avg_results('reports/{}-bert768-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_bert768 = embedded1 - twolayer_bert768\n",
    "\n",
    "    #bert-l2-prune30\n",
    "    twolayer_bertl2 = torch.tensor([get_avg_results('reports/{}-bert-l2-prune30-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,13)])\n",
    "    embedded2 = get_avg_results('reports/{}-bert-l2-prune30-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditiona_l2 = embedded2 - twolayer_bertl2\n",
    "\n",
    "    #distilbert-base-uncased\n",
    "    twolayer_distil = torch.tensor([get_avg_results('reports/{}-distilbert-base-uncased-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,7)])\n",
    "    embedded3 = get_avg_results('reports/{}-distilbert-base-uncased-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_distil = embedded3 - twolayer_distil\n",
    "\n",
    "    #MiniLMv2-L6-H768-distilled-from-BERT-Base\n",
    "    twolayer_minilmv2 = torch.tensor([get_avg_results('reports/{}-MiniLMv2-L6-H768-distilled-from-BERT-Base-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,7)])\n",
    "    embedded13 = get_avg_results('reports/{}-MiniLMv2-L6-H768-distilled-from-BERT-Base-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_minilmv2 = embedded13 - twolayer_minilmv2\n",
    "\n",
    "    #3-768-distilbert\n",
    "    twolayer_3_768 = torch.tensor([get_avg_results('reports/{}-3-768-en-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,4)])\n",
    "    embedded7 = get_avg_results('reports/{}-3-768-en-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_3_768 = embedded7 - twolayer_3_768\n",
    "\n",
    "    #6-768-distilbert\n",
    "    twolayer_6_768 = torch.tensor([get_avg_results('reports/{}-6-768-en-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,7)])\n",
    "    embedded4 = get_avg_results('reports/{}-6-768-en-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_6_768 = embedded4 - twolayer_6_768\n",
    "\n",
    "    #6-b128-distilbert\n",
    "    twolayer_6_b128 = torch.tensor([get_avg_results('reports/{}-6-b128-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,7)])\n",
    "    embedded5 = get_avg_results('reports/{}-6-b128-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional5_6_b128 = embedded5 - twolayer_6_b128\n",
    "\n",
    "    #6-768-b32-distilbert\n",
    "    twolayer_6_b32 = torch.tensor([get_avg_results('reports/{}-6-768-b32-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,7)])\n",
    "    embedded6 = get_avg_results('reports/{}-6-768-b32-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_6_b32 = embedded6 - twolayer_6_b32\n",
    "\n",
    "    #distilbert-b64-L6\n",
    "    twolayer_6_b64 = torch.tensor([get_avg_results('reports/{}-distilbert-b64-L6-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,7)])\n",
    "    embeddedb64 = get_avg_results('reports/{}-distilbert-b64-L6-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_6_b64 = embeddedb64 - twolayer_6_b64\n",
    "\n",
    "    #8-768-distilbert\n",
    "    twolayer_8_768 = torch.tensor([get_avg_results('reports/{}-8-768-en-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,9)])\n",
    "    embedded8 = get_avg_results('reports/{}-8-768-en-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_8_768 = embedded8 - twolayer_8_768\n",
    "\n",
    "    #8-b128-distilbert\n",
    "    twolayer_8_b128 = torch.tensor([get_avg_results('reports/{}-8-b128-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,9)])\n",
    "    embedded8b128 = get_avg_results('reports/{}-8-b128-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_8_b128 = embedded8b128 - twolayer_8_b128\n",
    "\n",
    "    #8-768-s9273-distilbert\n",
    "    twolayer_8_768_S9273 = torch.tensor([get_avg_results('reports/{}-8-768-en-s9273-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,9)])\n",
    "    embedded9 = get_avg_results('reports/{}-8-768-en-s9273-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_8_s9273 = embedded9 - twolayer_8_768_S9273\n",
    "\n",
    "    #distilbert-b64-L8\n",
    "    twolayer_8_b64 = torch.tensor([get_avg_results('reports/{}-distilbert-b64-L8-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,9)])\n",
    "    embedded8b64 = get_avg_results('reports/{}-distilbert-b64-L8-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_8_b64 = embedded8b64 - twolayer_8_b64\n",
    "\n",
    "    #10-768-distilbert\n",
    "    twolayer_10_768 = torch.tensor([get_avg_results('reports/{}-10-768-en-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,11)])\n",
    "    embedded10 = get_avg_results('reports/{}-10-768-en-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_10_768 = embedded10 - twolayer_10_768\n",
    "\n",
    "    #10-b128-distilbert\n",
    "    twolayer_10_b128 = torch.tensor([get_avg_results('reports/{}-10-b128-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,11)])\n",
    "    embedded11 = get_avg_results('reports/{}-10-b128-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_10_b128 = embedded11 - twolayer_10_b128\n",
    "\n",
    "    #distilbert-b64-L10\n",
    "    twolayer_10_b64 = torch.tensor([get_avg_results('reports/{}-distilbert-b64-L10-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,11)])\n",
    "    embedded10b64 = get_avg_results('reports/{}-distilbert-b64-L10-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_10_b64 = embedded10b64 - twolayer_10_b64\n",
    "\n",
    "    #12-768-distilbert\n",
    "    twolayer_12_768 = torch.tensor([get_avg_results('reports/{}-12-768-en-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,13)])\n",
    "    embedded12 = get_avg_results('reports/{}-12-768-en-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_12_768 = embedded12 - twolayer_12_768\n",
    "\n",
    "    #12-b128-distilbert\n",
    "    twolayer_12_b128 = torch.tensor([get_avg_results('reports/{}-12-b128-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,13)])\n",
    "    embedded12b128 = get_avg_results('reports/{}-12-b128-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_12_b128 = embedded12b128 - twolayer_12_b128\n",
    "\n",
    "    #distilbert-b64-L12\n",
    "    # twolayer_12_b64 = torch.tensor([get_avg_results('reports/{}-distilbert-b64-L12-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,13)])\n",
    "    # embedded12b64 = get_avg_results('reports/{}-distilbert-b64-L12-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    # conditional_12_b64 = embedded12b64 - twolayer_12_b64\n",
    "\n",
    "    \n",
    "\n",
    "    #print(label_accuracy)\n",
    "\n",
    "    #12 layer\n",
    "    x_range1 = list(range(1,13))\n",
    "    #3 layer\n",
    "    x_range2 = np.linspace(1,12,3)\n",
    "    #6 layer\n",
    "    x_range3 = np.linspace(1,12,6)\n",
    "    #8 layer\n",
    "    x_range4 = np.linspace(1,12,8)\n",
    "    #10 layer\n",
    "    x_range5 = np.linspace(1,12,10)\n",
    "\n",
    "    #plt.plot(x_range1, conditional_bert768, label=r'bert_768')\n",
    "    #plt.plot(x_range3, conditional_distil, label=r'distilbert-base-uncased')\n",
    "    #plt.plot(x_range3, conditional_minilmv2, label=r'MiniLMv2')\n",
    "    #plt.plot(x_range1, conditiona_l2, label=r'bert-l2-prune30')\n",
    "    plt.plot(x_range2, conditional_3_768, label=r'3-768-distilbert')\n",
    "    plt.plot(x_range3, conditional_6_768, label=r'6-768-distilbert')\n",
    "    plt.plot(x_range3, conditional_6_b32, label=r'6-768-b32-distilbert')\n",
    "    plt.plot(x_range3, conditional5_6_b128, label=r'6-b128-distilbert')\n",
    "    plt.plot(x_range3, conditional_6_b64, label=r'distilbert-b64-L6')\n",
    "    plt.plot(x_range4, conditional_8_768, label=r'8-768-distilbert')\n",
    "    plt.plot(x_range4, conditional_8_b128, label=r'8-b128-distilbert')\n",
    "    plt.plot(x_range4, conditional_8_b64, label=r'distilbert-b64-L8')\n",
    "    plt.plot(x_range4, conditional_8_s9273, label=r'8-768-s9273-distilbert')\n",
    "    plt.plot(x_range5, conditional_10_768, label=r'10-768-distilbert')\n",
    "    plt.plot(x_range5, conditional_10_b128, label=r'10-b128-distilbert')\n",
    "    plt.plot(x_range5, conditional_10_b64, label=r'distilbert-b64-L10')\n",
    "    plt.plot(x_range1, conditional_12_768, label=r'12-768-distilbert')\n",
    "    plt.plot(x_range1, conditional_12_b128, label=r'12-b128-distilbert')\n",
    "    #plt.plot(x_range1, conditional_12_b64, label=r'distilbert-b64-L12')\n",
    "\n",
    "    plt.title('V-Entropy of {} for variants of bert scaled for 12 layers'.format(task), fontsize = 12)\n",
    "\n",
    "    plt.ylabel('Accuracy', fontsize = 12)\n",
    "    plt.xlabel('Model layer', fontsize = 12)\n",
    "    #plt.legend()\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left', fontsize = \"small\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #plt.savefig('graphs/V-Entropy/V-Entropy for {} bert768 variants scaled to 12 layers.png'.format(task), dpi=200)\n",
    "    plt.savefig('graphs/V-Entropy/V-Entropy for {} wo bert768 scaled to 12 layers.png'.format(task), dpi=200)\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "77814856",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_conditional_combined('dep_rel')\n",
    "plot_conditional_combined('named_entities')\n",
    "plot_conditional_combined('ptb_pos')\n",
    "plot_conditional_combined('upos')\n",
    "plot_conditional_combined('word_sense')\n",
    "plot_conditional_combined('sst2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89cb6eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_b64_vs_b128_accuracy(task):\n",
    "    fig, ax = plt.subplots(figsize=(10,4.5))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "    #change depending on layers\n",
    "    ax.set_xticks(list(range(1,13)))\n",
    "    \"\"\"Makes a plot comparing layerwise bits of info\"\"\"\n",
    "\n",
    "    #6-b128-distilbert\n",
    "    label_accuracy_6_b128 = torch.tensor([get_avg_results('reports/{}-6-b128-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,7)])\n",
    "\n",
    "    #8-b128-distilbert\n",
    "    label_accuracy_8_b128 = torch.tensor([get_avg_results('reports/{}-8-b128-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,9)])\n",
    "\n",
    "    #10-b128-distilbert\n",
    "    label_accuracy_10_b128 = torch.tensor([get_avg_results('reports/{}-10-b128-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,11)])\n",
    "\n",
    "    #12-b128-distilbert\n",
    "    label_accuracy_12_b128 = torch.tensor([get_avg_results('reports/{}-12-b128-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,13)])\n",
    "\n",
    "    #distilbert-b64-L6\n",
    "    label_accuracy_6_b64 = torch.tensor([get_avg_results('reports/{}-distilbert-b64-L6-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,7)])\n",
    "\n",
    "    #distilbert-b64-L8\n",
    "    label_accuracy_8_b64 = torch.tensor([get_avg_results('reports/{}-distilbert-b64-L8-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,9)])\n",
    "\n",
    "    #distilbert-b64-L10\n",
    "    label_accuracy_10_b64 = torch.tensor([get_avg_results('reports/{}-distilbert-b64-L10-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,11)])\n",
    "\n",
    "    #distilbert-b64-L12\n",
    "    #label_accuracy_12_b64 = torch.tensor([get_avg_results('reports/{}-distilbert-b64-L12-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,13)])\n",
    "\n",
    "\n",
    "    #print(label_accuracy)\n",
    "\n",
    "    #12 layer\n",
    "    x_range1 = list(range(1,13))\n",
    "    #3 layer\n",
    "    x_range2 = np.linspace(1,12,3)\n",
    "    #6 layer\n",
    "    x_range3 = np.linspace(1,12,6)\n",
    "    #8 layer\n",
    "    x_range4 = np.linspace(1,12,8)\n",
    "    #10 layer\n",
    "    x_range5 = np.linspace(1,12,10)\n",
    "\n",
    "    plt.plot(x_range3, label_accuracy_6_b128, label=r'6-b128-distilbert')\n",
    "    plt.plot(x_range4, label_accuracy_8_b128, label=r'8-b128-distilbert')\n",
    "    plt.plot(x_range5, label_accuracy_10_b128, label=r'10-b128-distilbert')\n",
    "    plt.plot(x_range1, label_accuracy_12_b128, label=r'12-b128-distilbert')\n",
    "    plt.plot(x_range3, label_accuracy_6_b64, label=r'distilbert-b64-L6')\n",
    "    plt.plot(x_range4, label_accuracy_8_b64, label=r'distilbert-b64-L8')\n",
    "    plt.plot(x_range5, label_accuracy_10_b64, label=r'distilbert-b64-L10')\n",
    "    #plt.plot(x_range1, label_accuracy_12_b64, label=r'distilbert-b64-L12')\n",
    "\n",
    "    plt.title('Accuracy of {} for batch size 64 vs 128 of bert scaled for 12 layers'.format(task), fontsize = 12)\n",
    "\n",
    "    plt.ylabel('Accuracy', fontsize = 12)\n",
    "    plt.xlabel('Model layer', fontsize = 12)\n",
    "    #plt.legend()\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left', fontsize = \"small\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig('graphs/Accuracies/Accuracies for {} b64 vs b128 scaled to 12 layers.png'.format(task), dpi=200)\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8924eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_b64_vs_b128_accuracy('dep_rel')\n",
    "plot_b64_vs_b128_accuracy('named_entities')\n",
    "plot_b64_vs_b128_accuracy('ptb_pos')\n",
    "plot_b64_vs_b128_accuracy('upos')\n",
    "plot_b64_vs_b128_accuracy('word_sense')\n",
    "plot_b64_vs_b128_accuracy('sst2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9112e5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_b64_vs_b128_conditional(task):\n",
    "    fig, ax = plt.subplots(figsize=(10,4.5))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "    #change depending on layers\n",
    "    ax.set_xticks(list(range(1,13)))\n",
    "    \"\"\"Makes a plot comparing layerwise bits of info\"\"\"\n",
    "    #6-b128-distilbert\n",
    "    twolayer_6_b128 = torch.tensor([get_avg_results('reports/{}-6-b128-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,7)])\n",
    "    embedded1 = get_avg_results('reports/{}-6-b128-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_6_b128 = embedded1 - twolayer_6_b128\n",
    "\n",
    "    #8-b128-distilbert\n",
    "    twolayer_8_b128 = torch.tensor([get_avg_results('reports/{}-8-b128-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,9)])\n",
    "    embedded2 = get_avg_results('reports/{}-8-b128-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_8_b128 = embedded2 - twolayer_8_b128\n",
    "\n",
    "    #10-b128-distilbert\n",
    "    twolayer_10_b128 = torch.tensor([get_avg_results('reports/{}-10-b128-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,11)])\n",
    "    embedded3 = get_avg_results('reports/{}-10-b128-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_10_b128 = embedded3 - twolayer_10_b128\n",
    "\n",
    "    #12-b128-distilbert\n",
    "    twolayer_12_b128 = torch.tensor([get_avg_results('reports/{}-12-b128-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,13)])\n",
    "    embedded4 = get_avg_results('reports/{}-12-b128-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_12_b128 = embedded4 - twolayer_12_b128\n",
    "\n",
    "    #distilbert-b64-L6\n",
    "    twolayer_6_b64 = torch.tensor([get_avg_results('reports/{}-distilbert-b64-L6-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,7)])\n",
    "    embedded5 = get_avg_results('reports/{}-distilbert-b64-L6-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_6_b64 = embedded5 - twolayer_6_b64\n",
    "\n",
    "    #distilbert-b64-L8\n",
    "    twolayer_8_b64 = torch.tensor([get_avg_results('reports/{}-distilbert-b64-L8-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,9)])\n",
    "    embedded6 = get_avg_results('reports/{}-distilbert-b64-L8-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_8_b64 = embedded6 - twolayer_8_b64\n",
    "\n",
    "    #distilbert-b64-L10\n",
    "    twolayer_10_b64 = torch.tensor([get_avg_results('reports/{}-distilbert-b64-L10-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,11)])\n",
    "    embedded7 = get_avg_results('reports/{}-distilbert-b64-L10-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_10_b64 = embedded7 - twolayer_10_b64\n",
    "\n",
    "    #distilbert-b64-L12\n",
    "    #twolayer_12_b64 = torch.tensor([get_avg_results('reports/{}-distilbert-b64-L10-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,13)])\n",
    "    #embedded8 = get_avg_results('reports/{}-distilbert-b64-L10-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    #conditional_12_b64 = embedded8 - twolayer_12_b64\n",
    "\n",
    "    #12 layer\n",
    "    x_range1 = list(range(1,13))\n",
    "    #3 layer\n",
    "    x_range2 = np.linspace(1,12,3)\n",
    "    #6 layer\n",
    "    x_range3 = np.linspace(1,12,6)\n",
    "    #8 layer\n",
    "    x_range4 = np.linspace(1,12,8)\n",
    "    #10 layer\n",
    "    x_range5 = np.linspace(1,12,10)\n",
    "\n",
    "\n",
    "    plt.plot(x_range3, conditional_6_b128, label=r'6-b128-distilbert')\n",
    "    plt.plot(x_range4, conditional_8_b128, label=r'8-b128-distilbert')\n",
    "    plt.plot(x_range5, conditional_10_b128, label=r'10-b128-distilbert')\n",
    "    plt.plot(x_range1, conditional_12_b128, label=r'12-b128-distilbert')\n",
    "    plt.plot(x_range3, conditional_6_b64, label=r'6-b64-distilbert')\n",
    "    plt.plot(x_range4, conditional_8_b64, label=r'8-b64-distilbert')\n",
    "    plt.plot(x_range5, conditional_10_b64, label=r'10-b64-distilbert')\n",
    "    #plt.plot(x_range1, conditional_12_b128, label=r'12-b64-distilbert')\n",
    "\n",
    "    plt.title('V-Entropy of {} for batch size 64 vs 128 of bert scaled for 12 layers'.format(task), fontsize = 12)\n",
    "\n",
    "    plt.ylabel('Accuracy', fontsize = 12)\n",
    "    plt.xlabel('Model layer', fontsize = 12)\n",
    "    #plt.legend()\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left', fontsize = \"small\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig('graphs/V-Entropy/V-Entropy for {} b64 vs b128 scaled to 12 layers.png'.format(task), dpi=200)\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89960ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_b64_vs_b128_conditional('dep_rel')\n",
    "plot_b64_vs_b128_conditional('named_entities')\n",
    "plot_b64_vs_b128_conditional('ptb_pos')\n",
    "plot_b64_vs_b128_conditional('upos')\n",
    "plot_b64_vs_b128_conditional('word_sense')\n",
    "plot_b64_vs_b128_conditional('sst2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2035dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tests\n",
    "def plot_layerwise_adjacent(task, model):\n",
    "    fig, ax = plt.subplots(figsize=(6,4.5))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "    #change depending on layers\n",
    "    ax.set_xticks(list(range(1,7)))\n",
    "    \"\"\"Makes a plot comparing layerwise bits of info\"\"\"\n",
    "    #change range depending on layers of model\n",
    "    task_768_singlelayer_ventropy = torch.tensor([get_avg_results('reports/{}-{}-layer{}.yaml.results/dev.v_entropy'.format(task,model,i)) for i in range(1,7)])\n",
    "    task_768_twolayer_ventropy = torch.tensor([get_avg_results('reports/{}-{}-layer{}-{}.yaml.results/dev.v_entropy'.format(task,model,i-1,i)) for i in range(1,7)])\n",
    "    task_768_embedding_layer_ventropy = torch.tensor([get_avg_results('reports/{}-{}-layer{}.yaml.results/dev.v_entropy'.format(task,model,i-1)) for i in range(1,7)])\n",
    "\n",
    "    #print(task_768_singlelayer_ventropy)\n",
    "    #print(task_768_twolayer_ventropy)\n",
    "    #print(task_768_embedding_layer_ventropy)\n",
    "\n",
    "    #12 layer\n",
    "    #x_range = list(range(1,13))\n",
    "\n",
    "    #6 layer\n",
    "    x_range = list(range(1,7))\n",
    "\n",
    "    #3 layer\n",
    "    #x_range = list(range(1,4))\n",
    "\n",
    "    #8 layer\n",
    "    #x_range = list(range(1,9))\n",
    "\n",
    "    #10 layer\n",
    "    #x_range = list(range(1,11))\n",
    "\n",
    "    plt.plot(x_range, task_768_embedding_layer_ventropy-task_768_singlelayer_ventropy, label=r'baselined')\n",
    "    plt.plot(x_range, task_768_embedding_layer_ventropy-task_768_twolayer_ventropy, label=r'conditional')\n",
    "\n",
    "    #plot title\n",
    "    plt.title('{} {}'.format(model,task), fontsize = 12)\n",
    "\n",
    "    plt.ylabel('Bits', fontsize = 12)\n",
    "    plt.xlabel('Model layer', fontsize = 12)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #save figure in folder\n",
    "    plt.savefig('graphs/{0}/{0} {1} test.png'.format(model,task), dpi=200)\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_layerwise_adjacent('dep_rel','MiniLMv2-L6-H768-distilled-from-BERT-Base')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "bdcb088fcff89543e4432dbe4ebd8623f44d6acef8abb4374116cf95ee7b50fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
