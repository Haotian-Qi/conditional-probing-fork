{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04363091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.13.1-cp39-cp39-win_amd64.whl (162.5 MB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ilya jeff\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (4.2.0)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.13.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe and torchrun.exe are installed in 'c:\\Users\\Ilya Jeff\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 20.2.3; however, version 23.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Ilya Jeff\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "44c5a974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import glob\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"whitegrid\")\n",
    "mpl.rcParams['agg.path.chunksize'] = 10000\n",
    "\n",
    "#from matplotlib import rc\n",
    "#rc('text', usetex=True)\n",
    "mpl.rcParams['axes.titlesize'] = 'xx-large'\n",
    "mpl.rcParams['axes.labelsize'] = 'xx-large'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "033d4333",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun_rounds = ['round1', 'round2', 'round3']\n",
    "def get_avg_results(path_string):\n",
    "  \"\"\"\n",
    "  For experiments with multiple random training runs, collects all\n",
    "  training runs and averages their results\n",
    "  \"\"\"\n",
    "  result_list = []\n",
    "  for rerun_string in rerun_rounds:\n",
    "    completed_path = path_string.format(rerun_string)\n",
    "    if os.path.exists(completed_path):\n",
    "      result_list.append(float(open(completed_path).read()))\n",
    "  return sum(result_list)/len(result_list) if len(result_list) > 0 else -1.0\n",
    "  #print(result_list)\n",
    "  #return np.std(result_list) if len(result_list) > 0 else -1 #sum(result_list)/len(result_list) if len(result_list) > 0 else -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "93a1b410",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = torch.tensor([get_avg_results('reports/dep_rel-6-768-en-distilbert-layer{}.yaml.results/dev.v_entropy'.format(i)) for i in range(1,7)])\n",
    "#b = torch.tensor([float(open('reports/dep_rel-6-768-en-distilbert-layer{}.yaml.results/dev.v_entropy'.format(i)).read().strip()) for i in range(1,7)])\n",
    "#c = get_avg_results('reports/layer0.yaml.results/dev.v_entropy')\n",
    "#print(a)\n",
    "#print(b)\n",
    "\n",
    "#for i in range(1,7):\n",
    "#   print(i-1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "50abab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_layerwise_zero_baseline(task, model):\n",
    "    fig, ax = plt.subplots(figsize=(6,4.5))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "    #change depending on layers\n",
    "    ax.set_xticks(list(range(1,9)))\n",
    "    \"\"\"Makes a plot comparing layerwise bits of info\"\"\"\n",
    "    #change range depending on layers of model\n",
    "    task_768_singlelayer_ventropy = torch.tensor([get_avg_results('reports/{}-{}-layer{}.yaml.results/dev.v_entropy'.format(task,model,i)) for i in range(1,9)])\n",
    "    task_768_twolayer_ventropy = torch.tensor([get_avg_results('reports/{}-{}-layer{}-0.yaml.results/dev.v_entropy'.format(task,model,i)) for i in range(1,9)])\n",
    "    task_768_embedding_layer_ventropy = get_avg_results('reports/{}-{}-layer0.yaml.results/dev.v_entropy'.format(task,model))\n",
    "\n",
    "    #print(task_768_singlelayer_ventropy)\n",
    "    #print(task_768_twolayer_ventropy)\n",
    "    #print(task_768_embedding_layer_ventropy)\n",
    "\n",
    "    #12 layer\n",
    "    #x_range = list(range(1,13))\n",
    "\n",
    "    #6 layer\n",
    "    #x_range = list(range(1,7))\n",
    "\n",
    "    #3 layer\n",
    "    #x_range = list(range(1,4))\n",
    "\n",
    "    #8 layer\n",
    "    x_range = list(range(1,9))\n",
    "\n",
    "    #10 layer\n",
    "    #x_range = list(range(1,11))\n",
    "\n",
    "    plt.plot(x_range, task_768_embedding_layer_ventropy-task_768_singlelayer_ventropy, label=r'baselined')\n",
    "    plt.plot(x_range, task_768_embedding_layer_ventropy-task_768_twolayer_ventropy, label=r'conditional')\n",
    "\n",
    "    #plot title\n",
    "    plt.title('{} {}'.format(model,task), fontsize = 12)\n",
    "\n",
    "    plt.ylabel('Bits', fontsize = 12)\n",
    "    plt.xlabel('Model layer', fontsize = 12)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #save figure in folder\n",
    "    plt.savefig('graphs/{0}/{0} {1}.png'.format(model,task), dpi=200)\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "430bbd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(task, model):\n",
    "    fig, ax = plt.subplots(figsize=(6,4.5))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "    #change depending on layers\n",
    "    ax.set_xticks(list(range(1,9)))\n",
    "    \"\"\"Makes a plot accuracy\"\"\"\n",
    "    #change range depending on layers of model\n",
    "    label_accuracy = torch.tensor([get_avg_results('reports/{}-{}-layer{}.yaml.results/dev.label_acc'.format(task,model,i)) for i in range(1,9)])\n",
    "\n",
    "    #print(label_accuracy)\n",
    "\n",
    "    #12 layer\n",
    "    #x_range = list(range(1,13))\n",
    "\n",
    "    #6 layer\n",
    "    #x_range = list(range(1,7))\n",
    "\n",
    "    #3 layer\n",
    "    #x_range = list(range(1,4))\n",
    "\n",
    "    #8 layer\n",
    "    x_range = list(range(1,9))\n",
    "\n",
    "    #10 layer\n",
    "    #x_range = list(range(1,11))\n",
    "\n",
    "    plt.plot(x_range, label_accuracy)\n",
    "\n",
    "    #plot title\n",
    "    plt.title('{} {} accuracy'.format(model,task), fontsize = 12)\n",
    "\n",
    "    plt.ylabel('Accuracy', fontsize = 12)\n",
    "    plt.xlabel('Model layer', fontsize = 12)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #save figure in folder\n",
    "    plt.savefig('graphs/{0}/{0} {1} accuracy.png'.format(model,task), dpi=200)\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c9cf0bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_combined(task):\n",
    "    fig, ax = plt.subplots(figsize=(10,4.5))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "    #change depending on layers\n",
    "    ax.set_xticks(list(range(1,13)))\n",
    "    \"\"\"Makes a plot comparing layerwise bits of info\"\"\"\n",
    "    #bert768\n",
    "    label_accuracy_bert768 = torch.tensor([get_avg_results('reports/{}-bert768-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,13)])\n",
    "\n",
    "    #bert-l2-prune30\n",
    "    label_accuracy_bert_l2_prune30 = torch.tensor([get_avg_results('reports/{}-bert-l2-prune30-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,13)])\n",
    "\n",
    "    #distilbert-base-uncased\n",
    "    label_accuracy_distilbert_base_uncased = torch.tensor([get_avg_results('reports/{}-distilbert-base-uncased-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,7)])\n",
    "\n",
    "    #6-768-distilbert\n",
    "    label_accuracy_6_768 = torch.tensor([get_avg_results('reports/{}-6-768-en-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,7)])\n",
    "\n",
    "    #6-b128-distilbert\n",
    "    label_accuracy_6_b128 = torch.tensor([get_avg_results('reports/{}-6-b128-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,7)])\n",
    "\n",
    "    #6-768-b32-distilbert\n",
    "    label_accuracy_6_768_b32 = torch.tensor([get_avg_results('reports/{}-6-768-b32-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,7)])\n",
    "\n",
    "    #3-768-distilbert\n",
    "    label_accuracy_3_768 = torch.tensor([get_avg_results('reports/{}-3-768-en-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,4)])\n",
    "\n",
    "    #8-768-distilbert\n",
    "    label_accuracy_8_768 = torch.tensor([get_avg_results('reports/{}-8-768-en-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,9)])\n",
    "\n",
    "    #8-768-s9273-distilbert\n",
    "    label_accuracy_8_768_s9273 = torch.tensor([get_avg_results('reports/{}-8-768-en-s9273-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,9)])\n",
    "\n",
    "    #10-768-distilbert\n",
    "    label_accuracy_10_768 = torch.tensor([get_avg_results('reports/{}-10-768-en-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,11)])\n",
    "\n",
    "    #10-b128-distilbert\n",
    "    label_accuracy_10_b128 = torch.tensor([get_avg_results('reports/{}-10-b128-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,11)])\n",
    "\n",
    "    #12-768-distilbert\n",
    "    label_accuracy_12_768 = torch.tensor([get_avg_results('reports/{}-12-768-en-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,13)])\n",
    "\n",
    "    #MiniLMv2-L6-H768-distilled-from-BERT-Base\n",
    "    label_accuracy_minilmv2 = torch.tensor([get_avg_results('reports/{}-MiniLMv2-L6-H768-distilled-from-BERT-Base-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,7)])\n",
    "\n",
    "    #print(label_accuracy)\n",
    "\n",
    "    #12 layer\n",
    "    x_range1 = list(range(1,13))\n",
    "    #3 layer\n",
    "    x_range2 = np.linspace(1,12,3)\n",
    "    #6 layer\n",
    "    x_range3 = np.linspace(1,12,6)\n",
    "    #8 layer\n",
    "    x_range4 = np.linspace(1,12,8)\n",
    "    #10 layer\n",
    "    x_range5 = np.linspace(1,12,10)\n",
    "\n",
    "    #plt.plot(x_range1, label_accuracy_bert768, label=r'bert_768')\n",
    "    #plt.plot(x_range3, label_accuracy_distilbert_base_uncased, label=r'distilbert-base-uncased')\n",
    "    #plt.plot(x_range3, label_accuracy_minilmv2, label=r'MiniLMv2')\n",
    "    #plt.plot(x_range1, label_accuracy_bert_l2_prune30, label=r'bert-l2-prune30')\n",
    "    plt.plot(x_range2, label_accuracy_3_768, label=r'3-768-distilbert')\n",
    "    plt.plot(x_range3, label_accuracy_6_768, label=r'6-768-distilbert')\n",
    "    plt.plot(x_range3, label_accuracy_6_768_b32, label=r'6-768-b32-distilbert')\n",
    "    plt.plot(x_range3, label_accuracy_6_b128, label=r'6-b128-distilbert')\n",
    "    plt.plot(x_range4, label_accuracy_8_768, label=r'8-768-distilbert')\n",
    "    plt.plot(x_range4, label_accuracy_8_768_s9273, label=r'8-768-s9273-distilbert')\n",
    "    plt.plot(x_range5, label_accuracy_10_768, label=r'10-768-distilbert')\n",
    "    plt.plot(x_range5, label_accuracy_10_b128, label=r'10-b128-distilbert')\n",
    "    plt.plot(x_range1, label_accuracy_12_768, label=r'12-768-distilbert')\n",
    "\n",
    "    plt.title('Accuracy of {} for variants of bert scaled for 12 layers'.format(task), fontsize = 12)\n",
    "\n",
    "    plt.ylabel('Accuracy', fontsize = 12)\n",
    "    plt.xlabel('Model layer', fontsize = 12)\n",
    "    #plt.legend()\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left', fontsize = \"small\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #plt.savefig('graphs/Accuracies for {} bert768 variants scaled to 12 layers.png'.format(task), dpi=200)\n",
    "    plt.savefig('graphs/Accuracies for {} wo bert768.png scaled to 12 layers.png'.format(task), dpi=200)\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "61363f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conditional_combined(task):\n",
    "    fig, ax = plt.subplots(figsize=(10,4.5))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "    #change depending on layers\n",
    "    ax.set_xticks(list(range(1,13)))\n",
    "    \"\"\"Makes a plot comparing layerwise bits of info\"\"\"\n",
    "    #bert768\n",
    "    twolayer_bert768 = torch.tensor([get_avg_results('reports/{}-bert768-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,13)])\n",
    "    embedded1 = get_avg_results('reports/{}-bert768-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_bert768 = embedded1 - twolayer_bert768\n",
    "\n",
    "    #bert-l2-prune30\n",
    "    twolayer_bertl2 = torch.tensor([get_avg_results('reports/{}-bert-l2-prune30-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,13)])\n",
    "    embedded2 = get_avg_results('reports/{}-bert-l2-prune30-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditiona_l2 = embedded2 - twolayer_bertl2\n",
    "\n",
    "    #distilbert-base-uncased\n",
    "    twolayer_distil = torch.tensor([get_avg_results('reports/{}-distilbert-base-uncased-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,7)])\n",
    "    embedded3 = get_avg_results('reports/{}-distilbert-base-uncased-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_distil = embedded3 - twolayer_distil\n",
    "\n",
    "    #6-768-distilbert\n",
    "    twolayer_6_768 = torch.tensor([get_avg_results('reports/{}-6-768-en-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,7)])\n",
    "    embedded4 = get_avg_results('reports/{}-6-768-en-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_6_768 = embedded4 - twolayer_6_768\n",
    "\n",
    "    #6-b128-distilbert\n",
    "    twolayer_6_b128 = torch.tensor([get_avg_results('reports/{}-6-b128-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,7)])\n",
    "    embedded5 = get_avg_results('reports/{}-6-b128-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional5_6_b128 = embedded5 - twolayer_6_b128\n",
    "\n",
    "    #6-768-b32-distilbert\n",
    "    twolayer_6_b32 = torch.tensor([get_avg_results('reports/{}-6-768-b32-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,7)])\n",
    "    embedded6 = get_avg_results('reports/{}-6-768-b32-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_6_b32 = embedded6 - twolayer_6_b32\n",
    "\n",
    "    #3-768-distilbert\n",
    "    twolayer_3_768 = torch.tensor([get_avg_results('reports/{}-3-768-en-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,4)])\n",
    "    embedded7 = get_avg_results('reports/{}-3-768-en-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_3_768 = embedded7 - twolayer_3_768\n",
    "\n",
    "    #8-768-distilbert\n",
    "    twolayer_8_768 = torch.tensor([get_avg_results('reports/{}-8-768-en-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,9)])\n",
    "    embedded8 = get_avg_results('reports/{}-8-768-en-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_8_768 = embedded8 - twolayer_8_768\n",
    "\n",
    "    #8-768-s9273-distilbert\n",
    "    twolayer_8_768_S9273 = torch.tensor([get_avg_results('reports/{}-8-768-en-s9273-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,9)])\n",
    "    embedded9 = get_avg_results('reports/{}-8-768-en-s9273-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_8_s9273 = embedded9 - twolayer_8_768_S9273\n",
    "\n",
    "    #10-768-distilbert\n",
    "    twolayer_10_768 = torch.tensor([get_avg_results('reports/{}-10-768-en-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,11)])\n",
    "    embedded10 = get_avg_results('reports/{}-10-768-en-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_10_768 = embedded10 - twolayer_10_768\n",
    "\n",
    "    #10-b128-distilbert\n",
    "    twolayer_10_b128 = torch.tensor([get_avg_results('reports/{}-10-b128-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,11)])\n",
    "    embedded11 = get_avg_results('reports/{}-10-b128-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_10_b128 = embedded11 - twolayer_10_b128\n",
    "\n",
    "    #12-768-distilbert\n",
    "    twolayer_12_768 = torch.tensor([get_avg_results('reports/{}-12-768-en-distilbert-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,13)])\n",
    "    embedded12 = get_avg_results('reports/{}-12-768-en-distilbert-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_12_768 = embedded12 - twolayer_12_768\n",
    "\n",
    "    #MiniLMv2-L6-H768-distilled-from-BERT-Base\n",
    "    twolayer_minilmv2 = torch.tensor([get_avg_results('reports/{}-MiniLMv2-L6-H768-distilled-from-BERT-Base-layer{}-0.yaml.results/dev.v_entropy'.format(task,i)) for i in range(1,7)])\n",
    "    embedded13 = get_avg_results('reports/{}-MiniLMv2-L6-H768-distilled-from-BERT-Base-layer0.yaml.results/dev.v_entropy'.format(task))\n",
    "    conditional_minilmv2 = embedded13 - twolayer_minilmv2\n",
    "\n",
    "    #print(label_accuracy)\n",
    "\n",
    "    #12 layer\n",
    "    x_range1 = list(range(1,13))\n",
    "    #3 layer\n",
    "    x_range2 = np.linspace(1,12,3)\n",
    "    #6 layer\n",
    "    x_range3 = np.linspace(1,12,6)\n",
    "    #8 layer\n",
    "    x_range4 = np.linspace(1,12,8)\n",
    "    #10 layer\n",
    "    x_range5 = np.linspace(1,12,10)\n",
    "\n",
    "    plt.plot(x_range1, conditional_bert768, label=r'bert_768')\n",
    "    plt.plot(x_range3, conditional_distil, label=r'distilbert-base-uncased')\n",
    "    plt.plot(x_range3, conditional_minilmv2, label=r'MiniLMv2')\n",
    "    plt.plot(x_range1, conditiona_l2, label=r'bert-l2-prune30')\n",
    "    plt.plot(x_range2, conditional_3_768, label=r'3-768-distilbert')\n",
    "    plt.plot(x_range3, conditional_6_768, label=r'6-768-distilbert')\n",
    "    plt.plot(x_range3, conditional_6_b32, label=r'6-768-b32-distilbert')\n",
    "    plt.plot(x_range3, conditional5_6_b128, label=r'6-b128-distilbert')\n",
    "    plt.plot(x_range4, conditional_8_768, label=r'8-768-distilbert')\n",
    "    plt.plot(x_range4, conditional_8_s9273, label=r'8-768-s9273-distilbert')\n",
    "    plt.plot(x_range5, conditional_10_768, label=r'10-768-distilbert')\n",
    "    plt.plot(x_range5, conditional_10_b128, label=r'10-b128-distilbert')\n",
    "    plt.plot(x_range1, conditional_12_768, label=r'12-768-distilbert')\n",
    "\n",
    "    plt.title('V-Entropy of {} for variants of bert scaled for 12 layers'.format(task), fontsize = 12)\n",
    "\n",
    "    plt.ylabel('Accuracy', fontsize = 12)\n",
    "    plt.xlabel('Model layer', fontsize = 12)\n",
    "    #plt.legend()\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left', fontsize = \"small\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig('graphs/V-Entropy for {} bert768 variants scaled to 12 layers.png'.format(task), dpi=200)\n",
    "    #plt.savefig('graphs/V-Entropy for {} wo bert768.png scaled to 12 layers.png'.format(task), dpi=200)\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b21e8ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_layerwise_zero_baseline('dep_rel','8-b128-distilbert')\n",
    "plot_layerwise_zero_baseline('named_entities','8-b128-distilbert')\n",
    "plot_layerwise_zero_baseline('ptb_pos','8-b128-distilbert')\n",
    "plot_layerwise_zero_baseline('upos','8-b128-distilbert')\n",
    "plot_layerwise_zero_baseline('word_sense','8-b128-distilbert')\n",
    "plot_layerwise_zero_baseline('sst2','8-b128-distilbert')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "33f5a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy('dep_rel','8-b128-distilbert')\n",
    "plot_accuracy('named_entities','8-b128-distilbert')\n",
    "plot_accuracy('ptb_pos','8-b128-distilbert')\n",
    "plot_accuracy('upos','8-b128-distilbert')\n",
    "plot_accuracy('word_sense','8-b128-distilbert')\n",
    "plot_accuracy('sst2','8-b128-distilbert')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7eb0a5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_combined('dep_rel')\n",
    "plot_accuracy_combined('named_entities')\n",
    "plot_accuracy_combined('ptb_pos')\n",
    "plot_accuracy_combined('upos')\n",
    "plot_accuracy_combined('word_sense')\n",
    "plot_accuracy_combined('sst2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9d202e19",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (6,) and torch.Size([8])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ILYAJE~1\\AppData\\Local\\Temp/ipykernel_25124/2833072952.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_conditional_combined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dep_rel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplot_conditional_combined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'named_entities'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplot_conditional_combined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ptb_pos'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplot_conditional_combined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'upos'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplot_conditional_combined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'word_sense'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ILYAJE~1\\AppData\\Local\\Temp/ipykernel_25124/1979924070.py\u001b[0m in \u001b[0;36mplot_conditional_combined\u001b[1;34m(task)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_range1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconditiona_l2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr'bert-l2-prune30'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_range2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconditional_3_768\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr'3-768-distilbert'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_range3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconditional_8_768\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr'6-768-distilbert'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_range3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconditional_6_b32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr'6-768-b32-distilbert'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_range3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconditional5_6_b128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr'6-b128-distilbert'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ilya Jeff\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2767\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2768\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2769\u001b[1;33m     return gca().plot(\n\u001b[0m\u001b[0;32m   2770\u001b[0m         \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2771\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[1;32mc:\\Users\\Ilya Jeff\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1630\u001b[0m         \"\"\"\n\u001b[0;32m   1631\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1632\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1633\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1634\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ilya Jeff\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ilya Jeff\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[0;32m    499\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[0;32m    500\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (6,) and torch.Size([8])"
     ]
    }
   ],
   "source": [
    "plot_conditional_combined('dep_rel')\n",
    "plot_conditional_combined('named_entities')\n",
    "plot_conditional_combined('ptb_pos')\n",
    "plot_conditional_combined('upos')\n",
    "plot_conditional_combined('word_sense')\n",
    "plot_conditional_combined('sst2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2035dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tests\n",
    "def plot_layerwise_adjacent(task, model):\n",
    "    fig, ax = plt.subplots(figsize=(6,4.5))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "    #change depending on layers\n",
    "    ax.set_xticks(list(range(1,7)))\n",
    "    \"\"\"Makes a plot comparing layerwise bits of info\"\"\"\n",
    "    #change range depending on layers of model\n",
    "    task_768_singlelayer_ventropy = torch.tensor([get_avg_results('reports/{}-{}-layer{}.yaml.results/dev.v_entropy'.format(task,model,i)) for i in range(1,7)])\n",
    "    task_768_twolayer_ventropy = torch.tensor([get_avg_results('reports/{}-{}-layer{}-{}.yaml.results/dev.v_entropy'.format(task,model,i-1,i)) for i in range(1,7)])\n",
    "    task_768_embedding_layer_ventropy = torch.tensor([get_avg_results('reports/{}-{}-layer{}.yaml.results/dev.v_entropy'.format(task,model,i-1)) for i in range(1,7)])\n",
    "\n",
    "    #print(task_768_singlelayer_ventropy)\n",
    "    #print(task_768_twolayer_ventropy)\n",
    "    #print(task_768_embedding_layer_ventropy)\n",
    "\n",
    "    #12 layer\n",
    "    #x_range = list(range(1,13))\n",
    "\n",
    "    #6 layer\n",
    "    x_range = list(range(1,7))\n",
    "\n",
    "    #3 layer\n",
    "    #x_range = list(range(1,4))\n",
    "\n",
    "    #8 layer\n",
    "    #x_range = list(range(1,9))\n",
    "\n",
    "    #10 layer\n",
    "    #x_range = list(range(1,11))\n",
    "\n",
    "    plt.plot(x_range, task_768_embedding_layer_ventropy-task_768_singlelayer_ventropy, label=r'baselined')\n",
    "    plt.plot(x_range, task_768_embedding_layer_ventropy-task_768_twolayer_ventropy, label=r'conditional')\n",
    "\n",
    "    #plot title\n",
    "    plt.title('{} {}'.format(model,task), fontsize = 12)\n",
    "\n",
    "    plt.ylabel('Bits', fontsize = 12)\n",
    "    plt.xlabel('Model layer', fontsize = 12)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #save figure in folder\n",
    "    plt.savefig('graphs/{0}/{0} {1} test.png'.format(model,task), dpi=200)\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_layerwise_adjacent('dep_rel','MiniLMv2-L6-H768-distilled-from-BERT-Base')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "bdcb088fcff89543e4432dbe4ebd8623f44d6acef8abb4374116cf95ee7b50fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
