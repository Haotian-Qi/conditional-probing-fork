{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04363091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.13.1-cp39-cp39-win_amd64.whl (162.5 MB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ilya jeff\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (4.2.0)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.13.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe and torchrun.exe are installed in 'c:\\Users\\Ilya Jeff\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 20.2.3; however, version 23.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Ilya Jeff\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44c5a974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import glob\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"whitegrid\")\n",
    "mpl.rcParams['agg.path.chunksize'] = 10000\n",
    "\n",
    "#from matplotlib import rc\n",
    "#rc('text', usetex=True)\n",
    "mpl.rcParams['axes.titlesize'] = 'xx-large'\n",
    "mpl.rcParams['axes.labelsize'] = 'xx-large'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "033d4333",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun_rounds = ['round1', 'round2', 'round3']\n",
    "def get_avg_results(path_string):\n",
    "  \"\"\"\n",
    "  For experiments with multiple random training runs, collects all\n",
    "  training runs and averages their results\n",
    "  \"\"\"\n",
    "  result_list = []\n",
    "  for rerun_string in rerun_rounds:\n",
    "    completed_path = path_string.format(rerun_string)\n",
    "    if os.path.exists(completed_path):\n",
    "      result_list.append(float(open(completed_path).read()))\n",
    "  return sum(result_list)/len(result_list) if len(result_list) > 0 else -1.0\n",
    "  #print(result_list)\n",
    "  #return np.std(result_list) if len(result_list) > 0 else -1 #sum(result_list)/len(result_list) if len(result_list) > 0 else -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93a1b410",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = torch.tensor([get_avg_results('reports/dep_rel-6-768-en-distilbert-layer{}.yaml.results/dev.v_entropy'.format(i)) for i in range(1,7)])\n",
    "#b = torch.tensor([float(open('reports/dep_rel-6-768-en-distilbert-layer{}.yaml.results/dev.v_entropy'.format(i)).read().strip()) for i in range(1,7)])\n",
    "#c = get_avg_results('reports/layer0.yaml.results/dev.v_entropy')\n",
    "#print(a)\n",
    "#print(b)\n",
    "\n",
    "#for i in range(1,4):\n",
    "#   print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50abab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_layerwise_zero_baseline(task, model):\n",
    "    fig, ax = plt.subplots(figsize=(6,4.5))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "    #change depending on layers\n",
    "    ax.set_xticks(list(range(1,13)))\n",
    "    \"\"\"Makes a plot comparing layerwise bits of info\"\"\"\n",
    "    #change range depending on layers of model\n",
    "    task_768_singlelayer_ventropy = torch.tensor([get_avg_results('reports/{}-{}-layer{}.yaml.results/dev.v_entropy'.format(task,model,i)) for i in range(1,13)])\n",
    "    task_768_twolayer_ventropy = torch.tensor([get_avg_results('reports/{}-{}-layer{}-0.yaml.results/dev.v_entropy'.format(task,model,i)) for i in range(1,13)])\n",
    "    task_768_embedding_layer_ventropy = get_avg_results('reports/{}-{}-layer0.yaml.results/dev.v_entropy'.format(task,model))\n",
    "\n",
    "    #print(task_768_singlelayer_ventropy)\n",
    "    #print(task_768_twolayer_ventropy)\n",
    "    #print(task_768_embedding_layer_ventropy)\n",
    "\n",
    "    #12 layer\n",
    "    x_range = list(range(1,13))\n",
    "\n",
    "    #6 layer\n",
    "    #x_range = list(range(1,7))\n",
    "\n",
    "    #3 layer\n",
    "    #x_range = list(range(1,4))\n",
    "\n",
    "    #8 layer\n",
    "    #x_range = list(range(1,9))\n",
    "\n",
    "    #10 layer\n",
    "    #x_range = list(range(1,11))\n",
    "\n",
    "    plt.plot(x_range, task_768_embedding_layer_ventropy-task_768_singlelayer_ventropy, label=r'baselined')\n",
    "    plt.plot(x_range, task_768_embedding_layer_ventropy-task_768_twolayer_ventropy, label=r'conditional')\n",
    "\n",
    "    #plot title\n",
    "    plt.title('{} {}'.format(model,task), fontsize = 12)\n",
    "\n",
    "    plt.ylabel('Bits', fontsize = 12)\n",
    "    plt.xlabel('Model layer', fontsize = 12)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #save figure in folder\n",
    "    plt.savefig('graphs/{0}/{0} {1}.png'.format(model,task), dpi=200)\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "430bbd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(task, model):\n",
    "    fig, ax = plt.subplots(figsize=(6,4.5))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "    #change depending on layers\n",
    "    ax.set_xticks(list(range(1,13)))\n",
    "    \"\"\"Makes a plot accuracy\"\"\"\n",
    "    #change range depending on layers of model\n",
    "    label_accuracy = torch.tensor([get_avg_results('reports/{}-{}-layer{}.yaml.results/dev.label_acc'.format(task,model,i)) for i in range(1,13)])\n",
    "\n",
    "    #print(label_accuracy)\n",
    "\n",
    "    #12 layer\n",
    "    x_range = list(range(1,13))\n",
    "\n",
    "    #6 layer\n",
    "    #x_range = list(range(1,7))\n",
    "\n",
    "    #3 layer\n",
    "    #x_range = list(range(1,4))\n",
    "\n",
    "    #8 layer\n",
    "    #x_range = list(range(1,9))\n",
    "\n",
    "    #10 layer\n",
    "    #x_range = list(range(1,11))\n",
    "\n",
    "    plt.plot(x_range, label_accuracy)\n",
    "\n",
    "    #plot title\n",
    "    plt.title('{} {} accuracy'.format(model,task), fontsize = 12)\n",
    "\n",
    "    plt.ylabel('Accuracy', fontsize = 12)\n",
    "    plt.xlabel('Model layer', fontsize = 12)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #save figure in folder\n",
    "    plt.savefig('graphs/{0}/{0} {1} accuracy.png'.format(model,task), dpi=200)\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9cf0bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_combined(task):\n",
    "    fig, ax = plt.subplots(figsize=(6,4.5))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "    #change depending on layers\n",
    "    ax.set_xticks(list(range(1,13)))\n",
    "    \"\"\"Makes a plot comparing layerwise bits of info\"\"\"\n",
    "    #bert768\n",
    "    label_accuracy_bert768 = torch.tensor([get_avg_results('reports/{}-bert768-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,13)])\n",
    "\n",
    "    #bert-l2-prune30\n",
    "    label_accuracy_bert_l2_prune30 = torch.tensor([get_avg_results('reports/{}-bert-l2-prune30-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,13)])\n",
    "\n",
    "    #distilbert-base-uncased\n",
    "    label_accuracy_distilbert_base_uncased = torch.tensor([get_avg_results('reports/{}-distilbert-base-uncased-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,7)])\n",
    "\n",
    "    #6-768-distilbert\n",
    "    label_accuracy_6_768 = torch.tensor([get_avg_results('reports/{}-6-768-en-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,7)])\n",
    "\n",
    "    #6-b128-distilbert\n",
    "    label_accuracy_6_b128 = torch.tensor([get_avg_results('reports/{}-6-b128-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,7)])\n",
    "\n",
    "    #6-768-b32-distilbert\n",
    "    label_accuracy_6_768_b32 = torch.tensor([get_avg_results('reports/{}-6-768-b32-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,7)])\n",
    "\n",
    "    #3-768-distilbert\n",
    "    label_accuracy_3_768 = torch.tensor([get_avg_results('reports/{}-3-768-en-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,4)])\n",
    "\n",
    "    #8-768-distilbert\n",
    "    label_accuracy_8_768 = torch.tensor([get_avg_results('reports/{}-8-768-en-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,9)])\n",
    "\n",
    "    #8-768-s9273-distilbert\n",
    "    label_accuracy_8_768_s9273 = torch.tensor([get_avg_results('reports/{}-8-768-en-s9273-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,9)])\n",
    "\n",
    "    #10-768-distilbert\n",
    "    label_accuracy_10_768 = torch.tensor([get_avg_results('reports/{}-10-768-en-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,11)])\n",
    "\n",
    "    #10-b128-distilbert\n",
    "    label_accuracy_10_b128 = torch.tensor([get_avg_results('reports/{}-10-b128-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,11)])\n",
    "\n",
    "    #12-768-distilbert\n",
    "    label_accuracy_12_768 = torch.tensor([get_avg_results('reports/{}-12-768-en-distilbert-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,13)])\n",
    "\n",
    "    #MiniLMv2-L6-H768-distilled-from-BERT-Base\n",
    "    label_accuracy_minilmv2 = torch.tensor([get_avg_results('reports/{}-MiniLMv2-L6-H768-distilled-from-BERT-Base-layer{}.yaml.results/dev.label_acc'.format(task,i)) for i in range(1,7)])\n",
    "\n",
    "    #print(label_accuracy)\n",
    "\n",
    "    #12 layer\n",
    "    x_range1 = list(range(1,13))\n",
    "    #3 layer\n",
    "    x_range2 = list(range(1,4))\n",
    "    #6 layer\n",
    "    x_range3 = list(range(1,7))\n",
    "    #8 layer\n",
    "    x_range4 = list(range(1,9))\n",
    "    #10 layer\n",
    "    x_range5 = list(range(1,11))\n",
    "\n",
    "    plt.plot(x_range1, label_accuracy_bert768, label=r'bert_768')\n",
    "    plt.plot(x_range3, label_accuracy_distilbert_base_uncased, label=r'distilbert-base-uncased')\n",
    "    plt.plot(x_range3, label_accuracy_minilmv2, label=r'MiniLMv2')\n",
    "    plt.plot(x_range1, label_accuracy_bert_l2_prune30, label=r'bert-l2-prune30')\n",
    "    plt.plot(x_range2, label_accuracy_3_768, label=r'3-768-distilbert')\n",
    "    plt.plot(x_range3, label_accuracy_6_768, label=r'6-768-distilbert')\n",
    "    plt.plot(x_range3, label_accuracy_6_768_b32, label=r'6-768-b32-distilbert')\n",
    "    plt.plot(x_range3, label_accuracy_6_b128, label=r'6-b128-distilbert')\n",
    "    plt.plot(x_range4, label_accuracy_8_768, label=r'8-768-distilbert')\n",
    "    plt.plot(x_range4, label_accuracy_8_768_s9273, label=r'8-768-s9273-distilbert')\n",
    "    plt.plot(x_range5, label_accuracy_10_768, label=r'10-768-distilbert')\n",
    "    plt.plot(x_range5, label_accuracy_10_b128, label=r'10-b128-distilbert')\n",
    "    plt.plot(x_range1, label_accuracy_12_768, label=r'12-768-distilbert')\n",
    "\n",
    "    plt.title('Accuracy of {} for variants of bert'.format(task), fontsize = 12)\n",
    "\n",
    "    plt.ylabel('Accuracy', fontsize = 12)\n",
    "    plt.xlabel('Model layer', fontsize = 12)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig('graphs/Accuracies for {} bert768 variants.png'.format(task), dpi=200)\n",
    "    #plt.savefig('graphs/Accuracies for {} wo bert768.png'.format(task), dpi=200)\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b21e8ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_layerwise_zero_baseline('dep_rel','bert-wsd')\n",
    "plot_layerwise_zero_baseline('named_entities','bert-wsd')\n",
    "plot_layerwise_zero_baseline('ptb_pos','bert-wsd')\n",
    "plot_layerwise_zero_baseline('upos','bert-wsd')\n",
    "plot_layerwise_zero_baseline('word_sense','bert-wsd')\n",
    "plot_layerwise_zero_baseline('sst2','bert-wsd')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33f5a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy('dep_rel','bert-wsd')\n",
    "plot_accuracy('named_entities','bert-wsd')\n",
    "plot_accuracy('ptb_pos','bert-wsd')\n",
    "plot_accuracy('upos','bert-wsd')\n",
    "plot_accuracy('word_sense','bert-wsd')\n",
    "plot_accuracy('sst2','bert-wsd')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7eb0a5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_combined('dep_rel')\n",
    "plot_accuracy_combined('named_entities')\n",
    "plot_accuracy_combined('ptb_pos')\n",
    "plot_accuracy_combined('upos')\n",
    "plot_accuracy_combined('word_sense')\n",
    "plot_accuracy_combined('sst2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be467c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "bdcb088fcff89543e4432dbe4ebd8623f44d6acef8abb4374116cf95ee7b50fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
